{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_innotater import Innotater\n",
    "from jupyter_innotater.data import ImageInnotation, BoundingBoxInnotation, \\\n",
    "                                    MultiClassInnotation, BinaryClassInnotation, TextInnotation\n",
    "\n",
    "import numpy as np, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Filenames and Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5964ec9dae6a46afabe5894d8a0ae2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foodfns = sorted(os.listdir('./foods/'))\n",
    "targets = np.zeros((len(foodfns), 4), dtype='int') # (x,y,w,h) for each data row\n",
    "\n",
    "Innotater( ImageInnotation(foodfns, path='./foods'), BoundingBoxInnotation(targets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[204, 104,  64,  56],\n",
       "       [117, 127, 172, 133],\n",
       "       [169,  64,  74,  76],\n",
       "       [182, 106,  80,  77],\n",
       "       [161,  41, 148, 146],\n",
       "       [138, 136,  79,  70],\n",
       "       [ 78,  94, 143, 122],\n",
       "       [223,  41,  95, 113]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our newly-input bounding box data to disk - will be lost otherwise\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(targets, columns=['x','y','w','h'])\n",
    "df.insert(0,'filename', foodfns)\n",
    "df.to_csv('./bounding_boxes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avocado.jpg</td>\n",
       "      <td>204</td>\n",
       "      <td>104</td>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana.jpg</td>\n",
       "      <td>117</td>\n",
       "      <td>127</td>\n",
       "      <td>172</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garlic.jpg</td>\n",
       "      <td>169</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gingerbiscuit.jpg</td>\n",
       "      <td>182</td>\n",
       "      <td>106</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grapefruit.jpg</td>\n",
       "      <td>161</td>\n",
       "      <td>41</td>\n",
       "      <td>148</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lime.jpg</td>\n",
       "      <td>138</td>\n",
       "      <td>136</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onion.jpg</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "      <td>143</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweetpotato.jpg</td>\n",
       "      <td>223</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename    x    y    w    h\n",
       "0        avocado.jpg  204  104   64   56\n",
       "1         banana.jpg  117  127  172  133\n",
       "2         garlic.jpg  169   64   74   76\n",
       "3  gingerbiscuit.jpg  182  106   80   77\n",
       "4     grapefruit.jpg  161   41  148  146\n",
       "5           lime.jpg  138  136   79   70\n",
       "6          onion.jpg   78   94  143  122\n",
       "7    sweetpotato.jpg  223   41   95  113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Image Data and Multi-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "classes = ['vegetable', 'biscuit', 'fruit']\n",
    "foods = [cv2.imread('./foods/'+f) for f in foodfns]\n",
    "targets = [0] * len(foodfns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e80bee3bad3442cabe0f39a3f34fdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2 = Innotater(\n",
    "        ImageInnotation(foods, name='Food'), \n",
    "        MultiClassInnotation(targets, name='FoodType', classes=classes, desc='Food Type')\n",
    ")\n",
    "display(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 1, 2, 2, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert targets from a 1-dim array to one-hot representation - Innotater works with that just as well\n",
    "onehot_targets = np.squeeze(np.eye(np.array(targets).max()+1)[np.array(targets).reshape(-1)]); onehot_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9689b0f9c5744395adbdf6fde96cb417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Innotater(\n",
    "    ImageInnotation(foods, name='Food'), \n",
    "    MultiClassInnotation(onehot_targets, name='FoodType', classes=classes, desc='Food Type')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filenames and binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set image to display at a smaller width to make it more manageable - but bounding box co-ordinates would be relative to the unzoomed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65a5f3341504ac588bf2d33392b1679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isfruit_targets = (np.array(targets) == 2).astype('int')\n",
    "w3 = Innotater( ImageInnotation(foodfns, path='./foods', width=300),\n",
    "                BinaryClassInnotation(isfruit_targets, name='Is Fruit')\n",
    "              )\n",
    "display(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isfruit_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Filenames and Binary Classification plus Bounding Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use indexes attribute to limit display just to the fruits where we want to add bounding boxes. Drop the indexes property if you also want to be able to check non-fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa98f81fc5734682a52bf8d9fbb3da59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bboxes = np.zeros((len(foodfns),4), dtype='int')\n",
    "isfruits = np.expand_dims(isfruit_targets, axis=-1)\n",
    "\n",
    "suspected_fruits = isfruits == 1 # Or you can specify an array/list of int indices\n",
    "\n",
    "w6 = Innotater(\n",
    "        ImageInnotation(foodfns, name='Food', path='./foods'), \n",
    "        [ BinaryClassInnotation(isfruits, name='Is Fruit'),\n",
    "          BoundingBoxInnotation(bboxes, name='bbs', source='Food', desc='Food Type') ],\n",
    "    indexes = suspected_fruits\n",
    ")\n",
    "\n",
    "display(w6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, 203, 108,  61,  48],\n",
       "       [  1, 115, 131, 172, 127],\n",
       "       [  0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0],\n",
       "       [  1, 160,  44, 147, 142],\n",
       "       [  1, 136, 136,  81,  69],\n",
       "       [  0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.concatenate([isfruits,bboxes], axis=-1); result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image versus Image and Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fce1fda61844566880d8d57f235866e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = np.array([[1,0]] * 5) # One-hot format, defaulting to 0 class\n",
    "lfoods = foods[:5]\n",
    "rfoods = lfoods.copy()\n",
    "rfoods.reverse()\n",
    "\n",
    "w5 = Innotater([ImageInnotation(lfoods, name='Food 1'), ImageInnotation(rfoods, name='Food 2')], \n",
    "        [BinaryClassInnotation(targets, name='Are Equal')])\n",
    "display(w5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Image Data with named source of Bounding Boxes\n",
    "It is possible to draw multiple bounding boxes this way - one on each copy of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63034f4e52da41198d1725d0f1548dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foods2 = [f for f in foods]\n",
    "targets = np.array([[i*10,i*20,i*30,i*40] for i in range(len(foods))])\n",
    "targets2 = 2 * targets.copy() + 30\n",
    "\n",
    "w4 = Innotater([ImageInnotation(foods, name='Food1'), \n",
    "                ImageInnotation(foods2, name='Food2')], \n",
    "        [\n",
    "         BoundingBoxInnotation(targets, desc='Food Type1', source='Food1'), \n",
    "         BoundingBoxInnotation(targets2, desc='Food Type2', source='Food2')\n",
    "        ])\n",
    "display(w4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data - sentiment classification\n",
    "Movie reviews. In this example, numbers prefix the class names so you can keep input focus in the listbox and press 0, 1, or 2 to select the sentiment label, then press 'n' to advance to the next review (or 'p' to go back)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de3f3920f754c8b8f217e93a79521cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(Textarea(value='I really liked this movie', disabled=True),)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews = ['I really liked this movie', 'It was OK', 'Do not watch!', 'Was worth trying it']\n",
    "sentiments = [1] * len(reviews)\n",
    "sentiment_classes = ['0 - Positive', '1 - Neutral', '2 - Negative']\n",
    "\n",
    "Innotater(TextInnotation(reviews), MultiClassInnotation(sentiments, classes=sentiment_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I really liked this movie', '0 - Positive'),\n",
       " ('It was OK', '1 - Neutral'),\n",
       " ('Do not watch!', '2 - Negative'),\n",
       " ('Was worth trying it', '0 - Positive')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(reviews, [sentiment_classes[s] for s in sentiments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
